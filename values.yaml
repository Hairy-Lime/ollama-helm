# Production-ready values for Ollama deployment
replicaCount: 1

image:
  repository: ollama/ollama
  pullPolicy: IfNotPresent
  # Using empty tag to default to chart appVersion
  tag: ""

service:
  type: ClusterIP
  port: 11434
  # Enable if you need NodePort access
  # nodePort: 31434

# Configure resource limits for production
resources:
  requests:
    memory: "4Gi"
    cpu: "2000m"
  limits:
    memory: "8Gi"
    cpu: "4000m"

# Security settings
securityContext:
  capabilities:
    drop:
    - ALL
  # Adjust based on your security requirements
  # runAsNonRoot: true
  # runAsUser: 1000

podSecurityContext: {}
  # fsGroup: 2000

# Persistence configuration
persistentVolume:
  enabled: true
  size: 30Gi
  accessModes:
    - ReadWriteOnce
  # Specify your storage class if needed
  # storageClass: "standard"

# Health checks
livenessProbe:
  enabled: true
  path: /
  initialDelaySeconds: 60
  periodSeconds: 10
  timeoutSeconds: 5
  failureThreshold: 6
  successThreshold: 1

readinessProbe:
  enabled: true
  path: /
  initialDelaySeconds: 30
  periodSeconds: 5
  timeoutSeconds: 3
  failureThreshold: 6
  successThreshold: 1

# Ollama specific settings
ollama:
  gpu:
    enabled: false
    # Uncomment and adjust if using GPU
    # type: 'nvidia'  # or 'amd'
    # number: 1
    # For NVIDIA MIG support:
    # mig:
    #   enabled: false
    #   devices: {}
  models:
    # Specify models to pull at startup
    pull: []
    # Specify models to run at startup
    run: []
  # Default mount path
  mountPath: "/root/.ollama"

# Service account
serviceAccount:
  create: true
  automount: true

# Update strategy
updateStrategy:
  type: "Recreate"

# Pod management
podAnnotations: {}
podLabels: {}

# Autoscaling
autoscaling:
  enabled: false
  minReplicas: 1
  maxReplicas: 3
  targetCPUUtilizationPercentage: 80

# Optional ingress
ingress:
  enabled: false
  # className: "nginx"
  # annotations: {}
  # hosts:
  #   - host: ollama.local
  #     paths:
  #       - path: /
  #         pathType: Prefix
  # tls: []

# Additional environment variables
extraEnv: []
  # - name: OLLAMA_DEBUG
  #   value: "1"

# Node assignment
nodeSelector: {}
affinity: {}
tolerations: []